singleuser:
  podNameTemplate: "purdue-af-{userid}"
  uid: 0
  cmd: 
  image:
    name: "geddes-registry.rcac.purdue.edu/cms/cmsaf-alma8"
    tag: "0.8.3"
  profileList:
    - display_name: "JupyterLab based on CentOS7"
      description: "Container with pre-installed pythonic analysis software, as well as CVMFS and EOS mounts"
      kubespawner_override:
        image: "geddes-registry.rcac.purdue.edu/cms/cmsaf-centos7:0.3"
        node_selector: {'cms-af-dev': 'true'}
      profile_options:
        cpu:
          display_name: "CPUs"
          choices:
            1:
              display_name: "4"
              kubespawner_override:
                cpu_limit: 4
                cpu_guarantee: 4
        memory:
          display_name: "Memory"
          choices:
            1:
              display_name: "16 GB"
              kubespawner_override:
                mem_limit: "16G"
                mem_guarantee: "16G"
    - display_name: "JupyterLab based on CERN Alma8"
      default: true
      description: "Container with pre-installed pythonic analysis software, as well as CVMFS and EOS mounts"
      kubespawner_override:
        image: "geddes-registry.rcac.purdue.edu/cms/cmsaf-alma8:0.8.3"
        node_selector: {'cms-af-dev': 'true'}
        lifecycle_hooks:
          preStop:
            exec:
              command: ["bash", "-c", "rm -f eos-cern"]
      profile_options:
        cpu:
          display_name: "CPUs"
          choices:
            1:
              display_name: "4"
              kubespawner_override:
                cpu_limit: 4
                cpu_guarantee: 4
            2: 
              display_name: "16"
              kubespawner_override:
                cpu_limit: 16
                cpu_guarantee: 16
            3:
              display_name: "32"
              kubespawner_override:
                cpu_limit: 32
                cpu_guarantee: 32
        gpu:
          display_name: "GPUs"
          choices:
            1:
              display_name: "0"
              kubespawner_override:
                extra_resource_limits:
                  nvidia.com/mig-1g.5gb: "0"
            2:
              display_name: "1"
              kubespawner_override:
                extra_resource_limits:
                  nvidia.com/mig-1g.5gb: "1"
        memory:
          display_name: "Memory"
          choices:
            1:
              display_name: "16 GB"
              kubespawner_override:
                mem_limit: "16G"
                mem_guarantee: "16G"
            2:
              display_name: "32 GB"
              kubespawner_override:
                mem_limit: "32G" 
                mem_guarantee: "32G"
            3:
              display_name: "64 GB"
              kubespawner_override:
                mem_limit: "64G" 
                mem_guarantee: "64G"

    - display_name: "Start on af-a02 node (CERN Alma8)"
      default: false
      description: "Container with pre-installed pythonic analysis software, as well as CVMFS and EOS mounts"
      kubespawner_override:
        image: "geddes-registry.rcac.purdue.edu/cms/cmsaf-alma8:0.8.3"
        node_selector: {'testing': 'cmsaf'}
        lifecycle_hooks:
          preStop:
            exec:
              command: ["bash", "-c", "rm -f eos-cern"]
      profile_options:
        cpu:
          display_name: "CPUs"
          choices:
            1:
              display_name: "4"
              kubespawner_override:
                cpu_limit: 4
                cpu_guarantee: 4
            2: 
              display_name: "16"
              kubespawner_override:
                cpu_limit: 16
                cpu_guarantee: 16
            3:
              display_name: "32"
              kubespawner_override:
                cpu_limit: 32
                cpu_guarantee: 32
            4:
              display_name: "64"
              kubespawner_override:
                cpu_limit: 64
                cpu_guarantee: 64
            5:
              display_name: "128"
              kubespawner_override:
                cpu_limit: 128
                cpu_guarantee: 128
        memory:
          display_name: "Memory"
          choices:
            1:
              display_name: "16 GB"
              kubespawner_override:
                mem_limit: "16G"
                mem_guarantee: "16G"
            2:
              display_name: "32 GB"
              kubespawner_override:
                mem_limit: "32G" 
                mem_guarantee: "32G"
            3:
              display_name: "64 GB"
              kubespawner_override:
                mem_limit: "64G" 
                mem_guarantee: "64G"
            4:
              display_name: "256 GB"
              kubespawner_override:
                mem_limit: "256G" 
                mem_guarantee: "256G"

    - display_name: "Start on Hammer frontend (CERN Alma8)"
      default: false
      description: "Container with pre-installed pythonic analysis software, as well as CVMFS and EOS mounts"
      kubespawner_override:
        image: "geddes-registry.rcac.purdue.edu/cms/cmsaf-alma8:0.8.3"
        node_selector: {'testing': 'cmsfe'}
        lifecycle_hooks:
          preStop:
            exec:
              command: ["bash", "-c", "rm -f eos-cern"]
      profile_options:
        cpu:
          display_name: "CPUs"
          choices:
            1:
              display_name: "4"
              kubespawner_override:
                cpu_limit: 4
                cpu_guarantee: 4
            2: 
              display_name: "16"
              kubespawner_override:
                cpu_limit: 16
                cpu_guarantee: 16
            3:
              display_name: "32"
              kubespawner_override:
                cpu_limit: 32
                cpu_guarantee: 32
            4:
              display_name: "64"
              kubespawner_override:
                cpu_limit: 64
                cpu_guarantee: 64
            5:
              display_name: "128"
              kubespawner_override:
                cpu_limit: 128
                cpu_guarantee: 128
        memory:
          display_name: "Memory"
          choices:
            1:
              display_name: "16 GB"
              kubespawner_override:
                mem_limit: "16G"
                mem_guarantee: "16G"
            2:
              display_name: "32 GB"
              kubespawner_override:
                mem_limit: "32G" 
                mem_guarantee: "32G"
            3:
              display_name: "64 GB"
              kubespawner_override:
                mem_limit: "64G" 
                mem_guarantee: "64G"
            4:
              display_name: "256 GB"
              kubespawner_override:
                mem_limit: "256G" 
                mem_guarantee: "256G"

    - display_name: "Start on hammer-f013 node"
      default: false
      description: "Container with pre-installed pythonic analysis software, as well as CVMFS and EOS mounts"
      kubespawner_override:
        image: "geddes-registry.rcac.purdue.edu/cms/cmsaf-alma8:0.8.3"
        node_selector: {'testing': 'hammer'}
        lifecycle_hooks:
          preStop:
            exec:
              command: ["bash", "-c", "rm -f eos-cern"]
      profile_options:
        cpu:
          display_name: "CPUs"
          choices:
            1:
              display_name: "4"
              kubespawner_override:
                cpu_limit: 4
                cpu_guarantee: 4
            2: 
              display_name: "16"
              kubespawner_override:
                cpu_limit: 16
                cpu_guarantee: 16
            3:
              display_name: "32"
              kubespawner_override:
                cpu_limit: 32
                cpu_guarantee: 32
        gpu:
          display_name: "GPUs"
          choices:
            1:
              display_name: "0"
              kubespawner_override:
                extra_resource_limits:
                  nvidia.com/mig-1g.5gb: "0"
            2:
              display_name: "1"
              kubespawner_override:
                extra_resource_limits:
                  nvidia.com/mig-1g.5gb: "1"
        memory:
          display_name: "Memory"
          choices:
            1:
              display_name: "16 GB"
              kubespawner_override:
                mem_limit: "16G"
                mem_guarantee: "16G"
            2:
              display_name: "32 GB"
              kubespawner_override:
                mem_limit: "32G" 
                mem_guarantee: "32G"
            3:
              display_name: "64 GB"
              kubespawner_override:
                mem_limit: "64G" 
                mem_guarantee: "64G"

  defaultUrl: "/lab"
  extraEnv:
    JUPYTERHUB_SINGLEUSER_APP: "jupyter_server.serverapp.ServerApp"
    GRANT_SUDO: "yes"
    NAMESPACE: "cms-dev"
  networkPolicy:
    enabled: false
  storage:
    capacity: 25Gi
    dynamic:
      storageClass: geddes-standard-multinode
      storageAccessModes:
        - ReadWriteMany
    homeMountPath: /home/{legacy_escape_username}
    extraVolumes:
      - name: cvmfs
        hostPath: 
          path: /cvmfs
      - name: eos
        hostPath: 
          path: /eos
      - name: depot
        nfs:
          server: datadepot.rcac.purdue.edu
          path: /depot/cms
      - name: munge-key
        secret:
          secretName: munge-key
    extraVolumeMounts:
      - name: cvmfs
        mountPath: /cvmfs
        mountPropagation: HostToContainer
      - name: eos
        mountPath: /eos
        mountPropagation: HostToContainer
      - name: depot
        mountPath: /depot/cms
        mountPropagation: HostToContainer
      - mountPath: /etc/secrets/munge/
        name: munge-key
        readOnly: false
        mountPropagation: HostToContainer
  cloudMetadata:
    blockWithIptables: false

prePuller:
  hook:
    enabled: false
  continuous:
    enabled: false
hub:
  nodeSelector: {'cms-af-dev': 'true'}
  extraVolumes:
    - name: purdue-auth
      secret:
        secretName: purdue-auth
    - name: cern-auth
      secret:
        secretName: cern-auth
    - name: html-template
      secret:
        secretName: html-template
    - name: prometheus-storage-volume
      persistentVolumeClaim:
        claimName: prometheus-data-pvc
  extraVolumeMounts:
    - mountPath: /etc/secrets/purdue-auth/
      name: purdue-auth
      readOnly: true
    - mountPath: /etc/secrets/cern-auth/
      name: cern-auth
      readOnly: true
    - mountPath: /etc/secrets/html/
      name: html-template
      readOnly: true
    - name: prometheus-storage-volume
      mountPath: /prometheus/
  config:
    CILogonOAuthenticator:
      client_id: cilogon:/client_id/652ad741e63f7aa6c602e2a806c7c705
      client_secret: s-HM2wlBCMLJ0hy8LUakiD3lGcDOC6FSeluwDwL76epB67yFAGDEftwDGSUN_D_bdENpgaLqF2gBcx4YvW3V6w
      oauth_callback_url: https://cmsdev.geddes.rcac.purdue.edu/hub/oauth_callback
      username_claim: eppn
      enable_auth_state: true
      shown_idps:
        - https://cern.ch/login
        - https://idp.fnal.gov/idp/shibboleth
        - https://idp.purdue.edu/idp/shibboleth
    JupyterHub:
      authenticator_class: cilogon
  extraConfig:
    # Some additional config
    00-custom-spawner: |
      from oauthenticator.cilogon import CILogonOAuthenticator
      from jupyterhub.auth import LocalAuthenticator
      from tornado import web
      import pwd
      #class PurdueCILogonOAuthenticator(LocalAuthenticator, CILogonOAuthenticator):
      class PurdueCILogonOAuthenticator(CILogonOAuthenticator):
          async def authenticate(self, handler, data=None):
              import pprint
              ret = await super().authenticate(handler, data)
              print("in auth:")
              pprint.pprint(ret)
              name = ret['name']
              username, domain = ret['auth_state']['cilogon_user']['eppn'].split("@")
              fixedUsername = None

              if domain == 'purdue.edu':
                fixedUsername = username
                with open('/etc/secrets/purdue-auth/purdue-auth.txt') as file:
                  if not f"{username}\n" in file.readlines():
                    raise web.HTTPError(500, f"Access denied! User {username} is not in the list of authorized users.")

              elif domain == 'cern.ch':
                fixedUsername = username + "-cern"
                with open('/etc/secrets/cern-auth/cern-auth.txt') as file:
                  if not f"{username}\n" in file.readlines():
                    raise web.HTTPError(500, "Access denied! Only CMS members are allowed to log in with CERN credentials.")
              
              elif domain == 'fnal.gov':
                      fixedUsername = username + "-fnal"
              else:
                  raise web.HTTPError(500, "Failed to get username from CILogon")
              
              ret['name'] = fixedUsername
              ret['domain'] = domain
              return ret

      def passthrough_post_auth_hook(authenticator, handler, authentication):
          import pprint
          print("in post auth:")
          pprint.pprint(authentication)
          if authentication['auth_state'] is None:
              authentication['auth_state'] = {}
          authentication['auth_state']['name'] = authentication['name']
          authentication['auth_state']['domain'] = authentication['domain']
          return authentication

      c.JupyterHub.authenticator_class = PurdueCILogonOAuthenticator
      c.PurdueCILogonOAuthenticator.post_auth_hook = passthrough_post_auth_hook

    01-set-user-info: |
      from ldap3 import NTLM, SIMPLE, Server, Connection, ALL, SUBTREE
      import json
      import os
      import contextlib
      from kubernetes_asyncio import client

      NAMESPACE = "cms-dev"
      PROMETHEUS_DASK_TARGETS_JSON = "/prometheus/dask_targets.json"

      def ldap_lookup(username):
          url = "geddes-aux.rcac.purdue.edu"
          searchid = username.split('@')[0]
          baseDN = "ou=People,dc=rcac,dc=purdue,dc=edu"
          search_filter = "(uid={0}*)"
          #username = searchid[0]
          attrs = ['uidNumber','gidNumber']
          s = Server(host=url, use_ssl=True, get_info='ALL')
          #conn = Connection(s, user= DN, password= secret, auto_bind= True, version= 3, authentication='ANONYMOUS', \
          #client_strategy= 'SYNC', auto_referrals= True, check_names= True, read_only= False, lazy= False, raise_exceptions= False)
          s = Server(host= url ,use_ssl= True, get_info= 'ALL')
          conn = Connection(s, version = 3, authentication = "ANONYMOUS")
          conn.start_tls()
          print(conn.result)
          print(conn)
          conn.search(search_base = baseDN, search_filter = search_filter.format(username), search_scope = SUBTREE, attributes = attrs)
          ldap_result_id = json.loads(conn.response_to_json())
          print(ldap_result_id)
          result = ldap_result_id[u'entries'][0][u'attributes']
          uid_number = result[u'uidNumber']
          gid_number = result [u'gidNumber']
          print("UID",+ uid_number)
          print("GID", + gid_number)            
          return uid_number, gid_number

      def passthrough_auth_state_hook(spawner, auth_state):
          import pprint
          spawner.userdata = { "name": auth_state['name'],
                               "domain": auth_state['domain']
                             }
          print("GOT STATE:")
          pprint.pprint(spawner.userdata)
          domain = spawner.userdata['domain']
          username = spawner.userdata['name']
          spawner.environment["NB_USER"] = username
          if domain == "purdue.edu":
              uid,gid = ldap_lookup(username)
              spawner.environment["NB_UID"] = str(uid)
              spawner.environment["NB_GID"] = str(gid)
          else:
              spawner.environment["NB_UID"] = "1000"
              spawner.environment["NB_GID"] = "1000"

      async def my_pre_spawn_hook(spawner):
          api = client.CoreV1Api(client.ApiClient())
          dask_proxy = client.V1Service(
              api_version="v1",
              kind="Service",
              metadata=client.V1ObjectMeta(
                  name=f"{spawner.user.name}-dask-slurm-scheduler",
                  annotations={
                      "metallb.universe.tf/address-pool": "geddes-private-pool"
                  }
              ),
              spec=client.V1ServiceSpec(
                  selector={
                      "hub.jupyter.org/username": spawner.user.name
                  },
                  ports=[
                      client.V1ServicePort(
                          protocol="TCP",
                          port=8786,
                          name="dask-scheduler",
                          target_port=8786
                      ),
                      client.V1ServicePort(
                          protocol="TCP",
                          port=8787,
                          name="dask-dashboard",
                          target_port=8787
                      )
                  ],
                  type="LoadBalancer"
              )
          )
          with contextlib.suppress(client.exceptions.ApiException):
              await api.delete_namespaced_service(f"{spawner.user.name}-dask-slurm-scheduler", NAMESPACE)

          await api.create_namespaced_service(NAMESPACE, dask_proxy)
          spawner.log.info('Dask proxy configured for %s' % spawner.user.name)

          # Register target for Prometheus
          try:
              with open(PROMETHEUS_DASK_TARGETS_JSON, "r") as file:
                  dask_targets_json = json.load(file)
          except:
              dask_targets_json = [{"targets": []}]
          new_target = f'{spawner.user.name}-dask-slurm-scheduler.{NAMESPACE}.geddes.rcac.purdue.edu:8787'
          if new_target not in dask_targets_json[0]["targets"]:
              dask_targets_json[0]["targets"].append(new_target)
          with open(PROMETHEUS_DASK_TARGETS_JSON, "w") as file:
            json.dump(dask_targets_json, file)        

      async def my_post_stop_hook(spawner):
          api = client.CoreV1Api(client.ApiClient())
          with contextlib.suppress(client.exceptions.ApiException):
              await api.delete_namespaced_service(f"{spawner.user.name}-dask-slurm-scheduler", NAMESPACE)
              spawner.log.info('Dask proxy deleted for %s' % spawner.user.name)
          
          # Remove Prometheus target
          the_target = f'{spawner.user.name}-dask-slurm-scheduler.{NAMESPACE}.geddes.rcac.purdue.edu:8787'
          try:
              with open(PROMETHEUS_DASK_TARGETS_JSON, "r") as file:
                  dask_targets_json = json.load(file)
              if the_target in dask_targets_json[0]["targets"]:
                  dask_targets_json[0]["targets"] = [t for t in dask_targets_json[0]["targets"] if t!=the_target]
              with open(PROMETHEUS_DASK_TARGETS_JSON, "w") as file:
                  json.dump(dask_targets_json, file)
          except:
              print(f"Couldn't delete prometheus target {the_target}")

      c.KubeSpawner.auth_state_hook = passthrough_auth_state_hook
      c.KubeSpawner.pre_spawn_hook = my_pre_spawn_hook
      c.KubeSpawner.post_stop_hook = my_post_stop_hook
      c.KubeSpawner.notebook_dir = "~"
      c.KubeSpawner.working_dir = "/home/{legacy_escape_username}"
      c.KubeSpawner.disable_user_config = True
      c.KubeSpawner.http_timeout = 120
      c.KubeSpawner.start_timeout = 120
      c.KernelSpecManager.ensure_native_kernel = False
      c.JupyterHub.authenticate_prometheus = False
    templates: |
        c.JupyterHub.template_paths = ['/etc/secrets/html/']
  tolerations:
    - key: "hub.jupyter.org/dedicated"
      operator: "Equal"
      value: "cms-af"
      effect: "NoSchedule"

scheduling:
  userScheduler:
    enabled: false
  userPods:
      tolerations:
        - key: "hub.jupyter.org/dedicated"
          operator: "Equal"
          value: "cms-af"
          effect: "NoSchedule"

ingress:
 enabled: true
 hosts:
   - cmsdev.geddes.rcac.purdue.edu
cull:
#  concurrency: 10
 enabled: true
 every: 600
#  maxAge: 0
#  removeNamedServers: false
 timeout: 1209600
#  users: false

