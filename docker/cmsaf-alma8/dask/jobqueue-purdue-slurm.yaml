jobqueue:
  purdue-slurm:
    name: dask-worker

    # Dask worker options
    cores: 1 # Total number of cores per job
    memory: "2 GiB" # Total amount of memory per job
    processes: null # Number of Python processes per job

    interface: null # Network interface to use like eth0 or ib0
    death-timeout: 60 # Number of seconds to wait if a worker can not find a scheduler
    local-directory: null # Location of fast local storage like /scratch or $TMPDIR
    shared-temp-directory: null # Shared directory currently used to dump temporary security objects for workers
    extra: null # deprecated: use worker-extra-args
    worker-extra-args: [] # Additional arguments to pass to `dask-worker`

    # SLURM resource manager options
    shebang: "#!/usr/bin/env bash"
    queue: null
    account: null
    walltime: "00:30:00"
    env-extra: null
    job-script-prologue: []
    job-cpu: null
    job-mem: null
    job-extra: null
    job-extra-directives: []
    job-directives-skip: []
    log-directory: null
