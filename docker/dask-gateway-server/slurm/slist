#!/bin/bash
# ----------------------------------------------------------------------
# slist - List accessible Slurm accounts and their limits.
#
# Usage: slist [-h|--help] [-m] [-c|-g|-j|-l] [-a] [-v|q] [@server] [username]
#
# This is an initial attempt to substitute Torque-era `qlist` on Slurm turf.
# Note: IT IS NOT YOUR OLD QLIST!  It kind of resembles it, but only to a point!
#
# By Lev Gorenstein <lev@purdue.edu>, 2019
# ----------------------------------------------------------------------

# Some sanity settings
export PATH=/bin:/usr/bin 		# Limit the path to avoid surprises
set -o pipefail 			# Handle pipeline errors in a saner way.
set +o allexport 			# Make sure -a is disabled even if user
 					# had it (avoid 'Argument list too long' error)

VERSION="0.7.1" 			# Increment me!
PROGNAME=${BASH_SOURCE##*/}
LOG_TAG="slist"


# ----------------------------------------------------------------------
# Configuration and initialization.
# ----------------------------------------------------------------------
#
# Define default output mode.
OUTTYPE_DEF="cores" 			# ('cores', 'gpus', 'list', or 'jobs')

# Do we want "sfeatures" plug printed?
SHOW_SFEATURES=1 			# 0/1

# Configuration file.
# This file is sourced by the script and provides a rudimentary opportunity
# to override the above built-in output choices on specific clusters.
CONFFILE=/etc/slist.conf


# List and regexp of job states that are considered queued or running.
STATE_RUNNING="RUNNING,COMPLETING,CONFIGURING,STOPPED"
STATE_QUEUED="PENDING,REQUEUED,SPECIAL_EXIT"
STATE_HELD="REQUEUE_HOLD,SUSPENDED"
RE_RUNNING="${STATE_RUNNING//,/|}" 	# Carefully substitute ',' with '|'
RE_QUEUED="${STATE_QUEUED//,/|}" 	# Carefully substitute ',' with '|'
RE_HELD="${STATE_HELD//,/|}" 		# Carefully substitute ',' with '|'
RE_REASON_HELD="JobHeld"

# Some global variables we will need later
declare SACCTMGR LIMITS QOSLIMITS SINFO GPU_SINFO SQUEUE
declare -a ACCOUNTS
declare -a SACCTMGR_OPTS LIMITS_OPTS QOSLIMITS_OPTS SINFO_OPTS GPU_SINFO_OPTS SQUEUE_OPTS
SACCTMGR_BIN=/usr/bin/sacctmgr
SQUEUE_BIN=/usr/bin/squeue
SINFO_BIN=/usr/bin/sinfo
SCONTROL_BIN=/usr/bin/scontrol

# What is this Slurm's version?  Need for some version-specific behavior.
# Note: 1) only care about major and minor version (20.11.x becomes 20 and 11)
#       2) converting to pure numbers (23.02.x becomes 23 and 2)
read slurm_raw < <($SINFO_BIN --version)
read slurm_maj slurm_min < <(echo "$slurm_raw" | awk '{split($2, a, "."); print a[1]+0, a[2]+0}')

# ----------------------------------------------------------------------
# Auxillary functions.
# ----------------------------------------------------------------------
# Exit codes:
E_OK=0 					# Successful termination
E_CMDLINE=1 				# Bad command line
E_RUNTIME=2 				# Runtime error

warn() {
	# warn [-p] "message" ["message"...]
	# Send message(s) to stderr (yes, I don't like '>&2' in the main code).
	# With '-p' option, prefixes each message with "PROGNAME: " (and that's
	# pretty much the main raison-d'etre for this function vs. plain "echo").
	local msg
	local withname=0
	local opt OPTIND
	while getopts :p opt; do
		case $opt in
			p) withname=1;;
		esac
	done
	shift `expr $OPTIND - 1`

	# And now say it.
	for msg in "$@" ; do
		if [[ $withname -ne 0 ]]; then
			msg="$PROGNAME: $msg"
		fi
		echo -e "$msg" 1>&2
	done
}

clean_up() {
	# Perform pre-exit housekeeping
	return
}

error_exit() {
	# error_exit ["message" [status]]
	# Special case: an explicitly empty message ('') will not be printed.
	if [[ ! ($# -gt 0 && -z "$1") ]]; then
		warn -p "${1:-"Unknown Error"}"
	fi
	clean_up
	exit ${2:-$E_RUNTIME}
}

graceful_exit() {
	# graceful_exit [status]]
	clean_up
	exit ${1:-$E_OK}
}

signal_exit() {
	# Handle trapped signals
	case $1 in
		INT)
			error_exit "Program interrupted by user" ;;
		TERM)
			error_exit "Program terminated" ;;
		*)
			error_exit "Terminating on unknown signal" ;;
	esac
}

assert_command_is_available() {
	local cmd="$1"
	type "$cmd" >/dev/null 2>&1 || error_exit "Required command '$cmd' is not available, bailing out."
}

usage() {
	local LEADIN="  $PROGNAME"
	local spacer=$(printf "%${#LEADIN}s" '')
	echo "Usage:"
	# To break into several lines:
	#	echo -e "$LEADIN ....line1...."
	#	echo -e "$spacer ....line2...."
	echo -e "$LEADIN [-h|--help] [-m] [-c|-g|-j|-l] [-a] [-v]  [@server] [username]"
}


help_message() {
	# Yes, I don't like the '<<-' form, so indentation is somewhat off
	cat << _EOF_
$PROGNAME ver. $VERSION

List accessible Slurm accounts and their limits.

$(usage)

Positional arguments:
  @server 	Defaults to current cluster
  username	Defaults to current user

Options:
  -h, --help	 Display this help message and exit
  -m, --me	 My cores/GPUs/jobs only
  -c, --cores	 Count CPU cores (default on predominantly CPU-based clusters)
  -g, --gpus	 Count GPUs (default on GPU-based clusters like Gilbreth)
  -j, --jobs	 Count jobs (as opposed to cores or GPUs)
  -l, --list	 List accounts only (one comma-separated line)
  -a, --all	 Generate output for all accounts (not just my ones)
  -q, --quiet	 Suppress column headers and all non-essential output

Default output mode on this cluster: $OUTTYPE_DEF.

Exit status:
   $E_OK  - normal termination
   $E_CMDLINE  - error parsing command line
   $E_RUNTIME  - runtime error
_EOF_
	echo ""
	return
}


function populate_queue_variables() {
	# Populate global variables:
	#   SACCTMGR   - accounts information for the user (captured
	#                `sacctmgr show assoc` output)
	#   ACCOUNTS   - array of account names (extracted from SACCTMGR)
	#   LIMITS     - account core/GrtTRES/walltime limits information
	#                (extracted from SACCTMGR)
	#   QOSLIMITS  - QoS GrpTRES/walltime limits information for all
	#                defined QoS-es (extracted from SACCTMGR)
	#   EFFLIMITS  - effective walltime/cores/cpus limits information
	#                (combined from account and QoS limits... if defined,
	#                QoS trumps associations data)
	#   SINFO      - partitions' CPU state and other information
	#                (captured 'sinfo' output)
	#   GPU_SINFO  - partitions' GPU state information (also captured 'sinfo' output)
	#   SQUEUE     - jobs state information (captured 'squeue' output)
	#   SACCTMGR_OPTS, LIMITS_OPTS, QOSLIMITS_OPTS,SINFO_OPTS and SQUEUE_OPTS - arrays
	# 		 of command-line options for respective queries.
	#
	#   Arguments: 	none
	#   Output: 	none

	# Get accounts (i.e. labs) this user has access to.
	# The '-a/--all' mode is a bit trickier than that, though.
	SACCTMGR_OPTS+=( --noheader --parsable2 )
	SACCTMGR_OPTS+=( show associations wopl )
	if [[ -n $CLUSTER ]]; then
		SACCTMGR_OPTS+=( cluster="$CLUSTER" )
	fi

	local got_accounts=0
	if [[ $Opt_AllAccts -eq 0 ]]; then
		# Single user lookup - easy
		# Note: ignore accounts that do not have partitions assigned to them.
		SACCTMGR_OPTS+=( user="$WHO" )
		[[ $verbo -gt 0 ]] && warn "# SACCTMGR" "# $SACCTMGR_BIN ${SACCTMGR_OPTS[*]} | awk -F'|' '\$4'"
		SACCTMGR=$($SACCTMGR_BIN "${SACCTMGR_OPTS[@]}" | awk -F'|' '$4')
		got_accounts=$?
	else
		# All accounts mode.
		# Do not specify user=$WHO option (get *all* defined accounts
		# and associations for *all* users).  There will be lots of
		# duplicates in these tuples (everyone's got standby, etc -
		# note field 3 for each):
		#   #cluster|account|user|partition
		#      brown|rcac-a||
		#      brown|rcac-a|aai|brown-a
		#      brown|rcac-a|lev|brown-a
		#      .....
		#      brown|standby||
		#      brown|standby|aai|brown-standby
		#      brown|standby|lev|brown-standby
		# so we will replace user with 'ALL' before passing through
		# sort/uniq (and also discard ones without partition, as usual)
		# to get just:
		#      brown|rcac-a|ALL|brown-a
		#      brown|standby|ALL|brown-standby
		[[ $verbo -gt 0 ]] && warn "# SACCTMGR" "# $SACCTMGR_BIN ${SACCTMGR_OPTS[*]} | awk -F '|' -v OFS='|' '\$4 {\$3=ALL ; print}' | sort | uniq)"
		SACCTMGR=$($SACCTMGR_BIN "${SACCTMGR_OPTS[@]}" | awk -F '|' -v OFS='|' '$4 {$3="ALL" ; print}' | sort | uniq)
		got_accounts=$?
	fi
	if [[ $got_accounts -gt 0 ]]; then
		error_exit "Problem obtaining user accounts list, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$SACCTMGR" ""

	# Prepare sorted unique accounts list in various formats.
	readarray -t ACCOUNTS < <(echo "$SACCTMGR" | awk -F'|' '{print $2}' | sort | uniq)
	local ALIST=$(printf "%s\n" "${ACCOUNTS[@]}" | paste -s -d,) 	# Comma-sep.


	# -------------------------------------------------------------
	# Get GrpTRES and walltime limits, and default QoS (if any) for these
	# accounts (i.e. labs).
	# Almost like accounts lookup, except for the empty 'user=' trick.
	# Using '--parsable2' format because we can.
	LIMITS_OPTS+=( --noheader --parsable2)
	LIMITS_OPTS+=( show associations )
	if [[ -n $CLUSTER ]]; then
		LIMITS_OPTS+=( cluster="$CLUSTER" )
	fi
	LIMITS_OPTS+=( account="$ALIST" user= )
	LIMITS_OPTS+=( format="Account,GrpTRES,MaxWall,DefaultQOS" )
	[[ $verbo -gt 0 ]] && warn "# LIMITS"  "# $SACCTMGR_BIN ${LIMITS_OPTS[*]}"

	LIMITS=$($SACCTMGR_BIN "${LIMITS_OPTS[@]}")
	if [[ $? -gt 0 ]]; then
		error_exit "Problem obtaining accounts limits list, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$LIMITS" ""

	# Prepare sorted unique accounts list in various formats.
	readarray -t ACCOUNTS < <(echo "$SACCTMGR" | awk -F'|' '{print $2}' | sort | uniq)
	local ALIST=$(printf "%s\n" "${ACCOUNTS[@]}" | paste -s -d,) 	# Comma-sep.


	# -------------------------------------------------------------
	# Get QoS GrpTRES limits for all discovered QoS'es.
	QOSLIMITS_OPTS+=( --noheader --parsable2)
	QOSLIMITS_OPTS+=( show qos )
	if [[ -n $CLUSTER ]]; then
		LIMITS_OPTS+=( cluster="$CLUSTER" )
	fi
	QOSLIMITS_OPTS+=( format="Name,MaxWall,GrpTRES" )
	[[ $verbo -gt 0 ]] && warn "# QOSLIMITS" "# $SACCTMGR_BIN ${QOSLIMITS_OPTS[*]}"

	QOSLIMITS=$($SACCTMGR_BIN "${QOSLIMITS_OPTS[@]}")
	if [[ $? -gt 0 ]]; then
		error_exit "Problem obtaining default QoS limits list, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$QOSLIMITS" ""


	# -------------------------------------------------------------
	# Combine account limits (walltime and cpu/gpu from GrpTRES) in LIMITS
	# with their QoS counterparts from QOSLIMITS (because QoS values trump
	# account associations values if both are present).  Parse, combine
	# and present in a single easy to extract multiline string.
	# Output format:  "Account|DefaultQOS|MaxWall|MaxCores|MaxGPUs"
	EFFLIMITS=$(
		echo "$LIMITS" 						\
		| awk -F '|' -v IGNORECASE=1 -v QOSLIMITS="$QOSLIMITS" 	\
		      ' 						\
			BEGIN {
				# Generate auxiliary QoS array from original QOS string
				nqos=split(QOSLIMITS, buf, RS);
				for (i in buf) {
					split(buf[i], qbuf);
					QOS[qbuf[1], "Name"] = qbuf[1];
					QOS[qbuf[1], "WallTime"] = qbuf[2];
					QOS[qbuf[1], "GrpTRES"] = qbuf[3];
				}
			}

			# Helper function to extract number values from GrpTRES
			# Searches GrpTRES string for "name=##", returns number.
			# Note: "\<" is GAWK-ism, but that is ok (also note the
			# doubled-up backslash inside a string constant).
			function num_from_grptres(grptres,    name, re, buf) {
				re = "\\<" name "=([[:digit:]]+)";
				match(grptres, re, buf);
				return buf[1] + 0;
			}

			# And process incoming LIMITS line
			{
				ACCT=$1; ltres=$2; lwall=$3; DEFQOS=$4;
				lcores = num_from_grptres(ltres, "cpu");
				lgpus  = num_from_grptres(ltres, "gpu");
				qcores = 0; qgpus = 0; qwall = "";
				if (DEFQOS) {
					qcores = num_from_grptres(QOS[DEFQOS, "GrpTRES"], "cpu");
					qgpus  = num_from_grptres(QOS[DEFQOS, "GrpTRES"], "gpu");
					qwall  = QOS[DEFQOS, "WallTime"];
				}

				WALLTIME = qwall  ? qwall  : lwall;
				CORES    = qcores ? qcores : lcores;
				GPUS     = qgpus  ? qgpus  : lgpus ;

				printf("%s|%s|%s|%d|%d\n", ACCT, DEFQOS, WALLTIME, CORES, GPUS);
			}
		      ' 							\
	)
	if [[ $verbo -gt 0 ]]; then
	        warn "# EFFLIMITS combined from account and QoS data (Account|DefQoS|Walltime|Cores|GPUs)"
	        warn "$EFFLIMITS" ""
	fi


	# -------------------------------------------------------------
	# Get partitions info - main (CPU-based) flavor.
	# Careful output selection to avoid multiple lines per partition.
	SINFO_OPTS+=( --all --noheader )
	if [[ -n $CLUSTER ]]; then
		SINFO_OPTS+=( -M "$CLUSTER" )
	fi
	# Default nodelist width is too small, use an explicit wider one
	# and trim extraneous terminal spaces.
	SINFO_OPTS+=( -O 'PartitionName,CPUsState:30,Time,Nodelist:2048' )
	[[ $verbo -gt 0 ]] && warn "# SINFO" "# $SINFO_BIN ${SINFO_OPTS[*]} | grep -v '^CLUSTER:' | sed -e 's/ *$//'"

	SINFO=$($SINFO_BIN "${SINFO_OPTS[@]}" | grep -v '^CLUSTER:' | sed -e 's/ *$//')
	if [[ $? -gt 0 ]]; then
		error_exit "Problem obtaining partitions list, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$SINFO" ""


	# -------------------------------------------------------------
	# Get partitions info - additional GPU-based data.
	# This array contains A/I/O/T information for GPUs in each partition.
	#
	# Here sinfo could generate multiple lines per partition if certain
	# properties differed between nodes (e.g. GresUsed differ on allocated
	# vs. idle nodes).  With this in mind, post-process such multi-line
	# output and smartly join it back into single-line.
	# NB: if you change sinfo options here, make sure to edit the
	#     "assemble_gpuinfo_lines" function!
	GPU_SINFO_OPTS+=( --all --noheader --exact )
	if [[ -n $CLUSTER ]]; then
		GPU_SINFO_OPTS+=( -M "$CLUSTER" )
	fi
	# Default nodelist width is too small, use an explicit wider one
	# and trim extraneous terminal spaces.
	GPU_SINFO_OPTS+=( -O 'PartitionName,NodeAIOT:30,Gres,GresUsed,Nodelist:2048' )
	[[ $verbo -gt 0 ]] && warn "# GPU_SINFO" "# $SINFO_BIN ${GPU_SINFO_OPTS[*]} | grep -v '^CLUSTER:' | sed -e 's/ *$//' | assemble_gpuinfo_lines"

	GPU_SINFO=$($SINFO_BIN "${GPU_SINFO_OPTS[@]}" | grep -v '^CLUSTER:' | sed -e 's/ *$//' | assemble_gpuinfo_lines)
	if [[ $? -gt 0 ]]; then
		error_exit "Problem obtaining partitions GPU information, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$GPU_SINFO" ""



	# -------------------------------------------------------------
	# And capture jobs information from squeue
        # Note: using funny-looking "sed -e '/^CLUSTER:/d'" instead of
        # 	instinctive 'grep -v' because silly 'grep -v' would throw an
        # 	error status in the rare case of empty queue (zero output).
	# Note: as of Slurm 2023.02, '--array-unique' option is dropped
	#       (behavior rolled into main '--array').
	SQUEUE_OPTS+=( --noheader )
	if [[ -n $CLUSTER ]]; then
		SQUEUE_OPTS+=( -M "$CLUSTER" )
	fi
	SQUEUE_OPTS+=( --array )
	if [[ $slurm_maj -lt 23 ]]; then
		SQUEUE_OPTS+=( --array-unique )
	fi
	SQUEUE_OPTS+=( -t "$STATE_RUNNING,$STATE_QUEUED,$STATE_HELD" )
	SQUEUE_OPTS+=( -O "JobArrayID,Username,Partition,QOS:30,Account:30,State,NumCPUs,Tres-Alloc:120,ReasonList:120" )
	[[ $verbo -gt 0 ]] && warn "# SQUEUE" "# $SQUEUE_BIN ${SQUEUE_OPTS[*]} | grep -v '^CLUSTER:' | sed -e 's/ *$//'"

	# As an exception, using "sed -e '/^CLUSTER:/ d'" instead of usual
	# 'grep -v' here (because 'grep -v' exits with failure if there are
	# no jobs in the queue (like during maintenance), and 'pipefail'
	# pick it up and bail out. Having empty queues is rare, but ok (we
	# still wantto capture any squeue errors, of course).
	SQUEUE=$($SQUEUE_BIN "${SQUEUE_OPTS[@]}" | sed -e '/^CLUSTER:/ d' | sed -e 's/ *$//')
	if [[ $? -gt 0 ]]; then
		error_exit "Problem obtaining jobs list, bailing out"
	fi
	[[ $verbo -gt 0 ]] && warn "$SQUEUE" ""


	# Aren't we lucky to ge here?
	return $E_OK
}


function output_list() {
	# output_list "account" ["account"...]
	# Print output for '-l/--list' mode.
	#   Arguments: 	Slurm account(s) to print.
	#   Output: 	comma-separated list of accounts on stdout.

	# Easy, right?
	printf "%s\n" "$@" | paste -s -d,
	return $E_OK
}


function output_cores() {
	# output_cores "account" ["account"...]
	# Print slist output for the default cores-based mode.
	#   Arguments: 	Slurm account(s) to print.
	#   Output: 	Nicely-formatted table on stdout.
	#
	# TODO: Queued, Running and Free cores need proper accounting for
	# 	shared vs. non-shared nodes (the Oversubscribe flag).

	# Header first.
	FORMAT="%-14s %8s%9s%8s%8s %15s   %5s\n"
	if [[ $verbo -ge 0 ]]; then
		echo
		echo "                      Current Number of Cores                       Node"
		echo "Account           Total    Queue     Run    Free    Max Walltime    Type"
		echo "==============  =================================  ==============  ======"
	fi

	# Nothing to do if user has no accounts associated with them.
	if [[ -z $@ ]]; then
		[[ $verbo -ge 0 ]] && echo
		return $E_OK
	fi

	# Loop over all requested accounts
	for ACCT in "$@"; do
		# Extract partition name from SACCTMGR output line, then
		# use it to extract raw partition information from SINFO.
		PART=$(echo "$SACCTMGR" | awk -F'|' -v ACCT="$ACCT" '$2==ACCT {print $4}') 	# mack-nodes
		buf=$(echo "$SINFO" | awk -v PART="$PART" '$1==PART')
		NODELIST=$(echo "$buf" | awk '{print $4}') 	# mack-a[003-007]
		PSTAT=$(echo "$buf" | awk '{print $2}') 	# 0/160/16/176

		# Extract effective limits information from EFFLIMITS line.
		buf=$(echo "$EFFLIMITS" | awk -F'|' -v ACCT="$ACCT" '$1==ACCT')
		WALLTIME=$(echo "$buf" | awk -F'|' '{print $3}') 	# 1-00:00:00
		CORES=$(echo "$buf" | awk -F'|' '{print $4}') 		# 16

		# Total cores count for this account is given by effective limits.
		# Some accounts (e.g. standby or scholar) may not have CPU
		# limits attached to them (meaning that it's only limited by
		# the partition capacity).  Fall back to partition values then.
		# Standby especially is a very tricky case (for historic
		# reasons, qcontrol has a fake '20000' value for total standby
		# cores, and we must use partition information here instead of
		# the wrong GRPTRES).
		Total="$CORES"
		PartTotal=$(echo "$PSTAT" | cut -d/ -f4) 	# total
		PartOther=$(echo "$PSTAT" | cut -d/ -f3) 	# downed/drained
		if [[ -z $Total || $Total -eq 0 || $Total -gt "$PartTotal" ]]; then
			Total=$(( PartTotal - PartOther ))
		fi

		# Get Running and Queued cores counts in one pass from `squeue` output.
		# Note: for the sake of queued cores, consider held status
		# as queued (i.e. combine the two numbers).
		CORESTATS=$(
			echo "$SQUEUE" 					\
			| awk -v IGNORECASE=1 				\
			      -v ACCT="$ACCT" -v WHO="$WHO" 		\
			      -v RE_RUNNING="$RE_RUNNING"		\
			      -v RE_QUEUED="$RE_QUEUED"			\
			      -v RE_HELD="$RE_HELD"			\
			      -v RE_REASON_HELD="$RE_REASON_HELD" 	\
			      '						\
				# Ignore all but this account, then count
				$5 != ACCT {next}
				$6 ~ RE_RUNNING {
					RunningAll += $7;
					if ($2==WHO) RunningUser += $7;
				}
				$6 ~ RE_QUEUED && $9 !~ RE_REASON_HELD {
					QueuedAll += $7;
					if ($2==WHO) QueuedUser += $7;
				}
				$6 ~ RE_HELD || $9 ~ RE_REASON_HELD {
					HeldAll += $7;
					if ($2==WHO) HeldUser += $7;
				}
				END {
					printf("all|%d|%d\n",  QueuedAll+HeldAll, RunningAll);
					printf("user|%d|%d\n", QueuedUser+HeldUser, RunningUser);
				}
			      '						\
		)

		if [[ $verbo -gt 0 ]]; then
			warn "# CORESTATS (type|queued|running) for ACCT=$ACCT"
			warn "$CORESTATS"
		fi

		# Assign queued and running core counts based on 
		# regular vs '-m' mode.
		if [[ $Opt_Me -ne 0 ]]; then
			buf=$(echo "$CORESTATS" | grep '^user|')
		else
			buf=$(echo "$CORESTATS" | grep '^all|')
		fi
		Queued=$(echo "$buf" | cut -d'|' -f 2)
		Running=$(echo "$buf" | cut -d'|' -f 3)

		# And free cores is always what's left after all running.
		# Except for standby queue, which is special.
		RunningAll=$(echo "$CORESTATS" | grep '^all|' | cut -d'|' -f 3)
		if [[ "$ACCT" != standby* ]]; then
			# Regular queues are easy
			Free=$(( Total - RunningAll ))
		else
			# For standby, currently free cores are made of:
			#   (Total partition cores - down/drained nodes)
			#     - (all running standby cores)
			#     - (all cores on standby partition nodes that
			#        are occupied by NON-standby jobs)
			# Need to compute the last one: get list of nodes,
			# see what non-standby jobs are running on them,
			# count cores.  The number may be off, because timing,
			# because overlapping other partitions on heterogenous
			# clusters, because draining nodes... but it's ok.
			if [[ $verbo -gt 0 ]]; then
 				echo "# Counting standby cores used by owners' jobs"
				echo "# $SINFO_BIN -p $PART -h -o %N | xargs -I NODES $SQUEUE_BIN ${SQUEUE_OPTS[*]} --state=$STATE_RUNNING -w NODES | awk ...."
			fi
			StandbyCoresUsedByOwner=$(
 				$SINFO_BIN -p "$PART" -h -o %N 	\
				| xargs -I NODES $SQUEUE_BIN "${SQUEUE_OPTS[@]}" --state="$STATE_RUNNING" -w NODES \
				| awk -v IGNORECASE=1 			\
				      -v ACCT="$ACCT"			\
				      -v RE_RUNNING="$RE_RUNNING"	\
				      '					\
					# Ignore this account, then count
					$5 == ACCT {next}
					$5 == "testpbs" {next}
					$6 ~ RE_RUNNING {
						RunningOwner += $7;
					}
					END {printf("%d\n", RunningOwner)}
				      '					\
			)
			Free=$(( Total - RunningAll - StandbyCoresUsedByOwner ))

			if [[ $verbo -gt 0 ]]; then
				warn "# Special account: $ACCT ($PART)"
				warn "# Total=$Total"
				warn "# RunningAll=$RunningAll"
				warn "# StandbyCoresUsedByOwner=$StandbyCoresUsedByOwner"
				warn "# Free=(Total - RunningAll - StandbyCoresUsedByOwner) = ($Total - $RunningAll - $StandbyCoresUsedByOwner) = $Free"
			fi
		fi

		# Sanity check
		if (( "$Free" < 0 )); then
			Free=0
		fi

		# Brush-up nodelist into comma-separated node types
		NODETYPES=$(nodelist2types "$NODELIST")

		# And print!
		printf  "$FORMAT" "$ACCT" "$Total" "$Queued" "$Running" "$Free" \
			"$WALLTIME" "${NODETYPES^^*}"
	done
	[[ $verbo -ge 0 ]] && echo
	return $E_OK
}


function output_jobs() {
	# output_jobs "account" ["account"...]
	# Print slist output for '-j/--jobs' mode.
	#   Arguments: 	Slurm account(s) to print.
	#   Output: 	Nicely-formatted table on stdout.

	# Header first.
	FORMAT="%-14s %8s%9s%8s%8s %15s   %5s\n"
	if [[ $verbo -ge 0 ]]; then
		echo
		echo "                      Current Number of Jobs                        Node"
		echo "Account           Total    Queue     Run    Hold    Max Walltime    Type"
		echo "==============  =================================  ==============  ======"
	fi

	# Nothing to do if user has no accounts associated with them.
	if [[ -z $@ ]]; then
		[[ $verbo -ge 0 ]] && echo
		return $E_OK
	fi

	# Loop over all requested accounts
	for ACCT in "$@"; do
		# Extract partition name from SACCTMGR output line, then
		# use it to extract raw partition information from SINFO.
		PART=$(echo "$SACCTMGR" | awk -F'|' -v ACCT="$ACCT" '$2==ACCT {print $4}') 	# mack-nodes
		buf=$(echo "$SINFO" | awk -v PART="$PART" '$1==PART')
		NODELIST=$(echo "$buf" | awk '{print $4}') 	# mack-a[003-007]

		# Extract raw limits information from LIMITS output line.
		buf=$(echo "$LIMITS" | awk -F'|' -v ACCT="$ACCT" '$1==ACCT')
		WALLTIME=$(echo "$buf" | awk -F'|' '{print $3}') 	# 1-00:00:00

		# Get all jobs counts in one pass from `squeue` output.
		# SQUEUE_OPTS+=( -O "JobArrayID,Username,Partition,QOS,Account,State,NumCPUs,Tres-Alloc,ReasonList" )
		JOBSTATS=$(
			echo "$SQUEUE" 					\
			| awk -v IGNORECASE=1 				\
			      -v ACCT="$ACCT" -v WHO="$WHO" 		\
			      -v RE_RUNNING="$RE_RUNNING"		\
			      -v RE_QUEUED="$RE_QUEUED"			\
			      -v RE_HELD="$RE_HELD"			\
			      -v RE_REASON_HELD="$RE_REASON_HELD" 	\
			      '						\
				# Ignore all but this account, then count
				$5 != ACCT {next}
				NF {
					TotalAll++;
					if ($2==WHO) TotalUser++;
				}
				$6 ~ RE_RUNNING {
					RunningAll++;
					if ($2==WHO) RunningUser++;
				}
				$6 ~ RE_QUEUED && $9 !~ RE_REASON_HELD {
					QueuedAll++;
					if ($2==WHO) QueuedUser++;
				}
				$6 ~ RE_HELD || $9 ~ RE_REASON_HELD {
					HeldAll++;
					if ($2==WHO) HeldUser++;
				}
				END {
					printf("all|%d|%d|%d|%d\n", TotalAll, QueuedAll, RunningAll, HeldAll);
					printf("user|%d|%d|%d|%d\n", TotalUser, QueuedUser, RunningUser, HeldUser);
				}
			      '						\
		)

		if [[ $verbo -gt 0 ]]; then
			warn "# JOBSTATS (type|queued|running) for ACCT=$ACCT"
			warn "$JOBSTATS"
		fi

		# Assign relevant job counts based on regular vs '-m' mode.
		# Easy-peasy for jobs.
		if [[ $Opt_Me -ne 0 ]]; then
			buf=$(echo "$JOBSTATS" | grep '^user|')
		else
			buf=$(echo "$JOBSTATS" | grep '^all|')
		fi
		Total=$(echo "$buf" | cut -d'|' -f 2)
		Queued=$(echo "$buf" | cut -d'|' -f 3)
		Running=$(echo "$buf" | cut -d'|' -f 4)
		Held=$(echo "$buf" | cut -d'|' -f 5)

		# Brush-up nodelist into comma-separated node types
		NODETYPES=$(nodelist2types "$NODELIST")

		# And print!
		printf  "$FORMAT" "$ACCT" "$Total" "$Queued" "$Running" "$Held" \
			"$WALLTIME" "${NODETYPES^^*}"
	done
	[[ $verbo -ge 0 ]] && echo
	return $E_OK
}


function output_gpus() {
	# output_gpus "account" ["account"...]
	# Print slist output for the GPUs-based mode (from per-account QoS)
	#   Arguments: 	Slurm account(s) to print.
	#   Output: 	Nicely-formatted table on stdout.
	#

	# Header first.
	FORMAT="%-14s %8s%9s%8s%8s %15s   %5s\n"
	if [[ $verbo -ge 0 ]]; then
		echo
		echo "                      Current Number of GPUs                        Node"
		echo "Account           Total    Queue     Run    Free    Max Walltime    Type"
		echo "==============  =================================  ==============  ======"
	fi

	# Nothing to do if user has no accounts associated with them.
	if [[ -z $@ ]]; then
		[[ $verbo -ge 0 ]] && echo
		return $E_OK
	fi

	# Loop over all requested accounts
	for ACCT in "$@"; do
		# Extract partition name from SACCTMGR output line, then
		# use it to extract raw partition information from GPU_SINFO
		# (not from regular SINFO).
		PART=$(echo "$SACCTMGR" | awk -F'|' -v ACCT="$ACCT" '$2==ACCT {print $4}') 	# mack-nodes
		buf=$(echo "$GPU_SINFO" | awk -v PART="$PART" '$1==PART')
		NODELIST=$(echo "$buf" | awk '{print $3}') 	# mack-a[003-007]
		PSTAT=$(echo "$buf" | awk '{print $2}') 	# 0/160/16/176

		# Extract effective limits information from EFFLIMITS line.
		buf=$(echo "$EFFLIMITS" | awk -F'|' -v ACCT="$ACCT" '$1==ACCT')
		WALLTIME=$(echo "$buf" | awk -F'|' '{print $3}') 	# 1-00:00:00
		GPUS=$(echo "$buf" | awk -F'|' '{print $5}') 		# 2

		# Total GPU count for this account is given by effective limits.
		# Some accounts (e.g. standby or scholar) may not have GPU
		# limits attached to them (meaning that it's only limited by
		# the partition capacity).  Fall back to partition values then.
		# Standby especially is a very tricky case (for historic
		# reasons, qcontrol has a fake '20000' value for total standby
		# cores, and we must use partition information here instead of
		# the wrong GRPTRES).
		Total="$GPUS"
		PartTotal=$(echo "$PSTAT" | cut -d/ -f4) 	# total
		PartOther=$(echo "$PSTAT" | cut -d/ -f3) 	# downed/drained
		if [[ -z $Total || $Total -eq 0 || $Total -gt "$PartTotal" ]]; then
			Total=$(( PartTotal - PartOther ))
		fi

		# Get Running and Queued GPU counts in one pass from 'squeue' output.
		# Note: for the sake of queued GPUs, consider held status
		# as queued (i.e. combine the two numbers).
		GPUSTATS=$(
			echo "$SQUEUE" 					\
			| awk -v IGNORECASE=1 				\
			      -v ACCT="$ACCT" -v WHO="$WHO" 		\
			      -v RE_RUNNING="$RE_RUNNING"		\
			      -v RE_QUEUED="$RE_QUEUED"			\
			      -v RE_HELD="$RE_HELD"			\
			      -v RE_REASON_HELD="$RE_REASON_HELD" 	\
			      '							\
				# Ignore all but this account, then count
				$5 != ACCT {next}

				# Extract GPU counts from the Tres-Alloc field.
				# Note: this is a GAWK-ism, but that is ok.
				{
					match($8, /gpu=([0-9]+)/, buf);
					gpus = buf[1] + 0;
				}
				$6 ~ RE_RUNNING {
					RunningAll += gpus;
					if ($2==WHO) RunningUser += gpus;
				}
				$6 ~ RE_QUEUED && $9 !~ RE_REASON_HELD {
					QueuedAll += gpus;
					if ($2==WHO) QueuedUser += gpus;
				}
				$6 ~ RE_HELD || $9 ~ RE_REASON_HELD {
					HeldAll += gpus;
					if ($2==WHO) HeldUser += gpus;
				}
				END {
					printf("all|%d|%d\n",  QueuedAll+HeldAll, RunningAll);
					printf("user|%d|%d\n", QueuedUser+HeldUser, RunningUser);
				}
			      '						\
		)

		if [[ $verbo -gt 0 ]]; then
			warn "# GPUSTATS (type|queued|running) for ACCT=$ACCT"
			warn "$GPUSTATS"
		fi

		# Assign queued and running core counts based on 
		# regular vs '-m' mode.
		if [[ $Opt_Me -ne 0 ]]; then
			buf=$(echo "$GPUSTATS" | grep '^user|')
		else
			buf=$(echo "$GPUSTATS" | grep '^all|')
		fi
		Queued=$(echo "$buf" | cut -d'|' -f 2)
		Running=$(echo "$buf" | cut -d'|' -f 3)

		# And free cores is always what's left after all running.
		# Except for standby queue, which is special.
		RunningAll=$(echo "$GPUSTATS" | grep '^all|' | cut -d'|' -f 3)
		if [[ "$ACCT" != standby* && "$ACCT" != partner* ]]; then
			# Regular queues are easy
			Free=$(( Total - RunningAll ))
		else
			# For standby, currently free GPUs are made of:
			#   (Total partition GPUs - down/drained nodes)
			#     - (all running standby GPUs)
			#     - (all GPUs on standby partition nodes that
			#        are occupied by NON-standby jobs)
			# Need to compute the last one: get list of nodes,
			# see what non-standby jobs are running on them,
			# count GPUs.  The number may be off, because timing,
			# because overlapping other partitions on heterogenous
			# clusters, because draining nodes... but it's ok.
			if [[ $verbo -gt 0 ]]; then
 				echo "# Counting standby GPUs used by owners' jobs"
				echo "# $SINFO_BIN -p $PART -h -o %N | xargs -I NODES $SQUEUE_BIN ${SQUEUE_OPTS[*]} --state=$STATE_RUNNING -w NODES | awk ...."
			fi
			StandbyGPUsUsedByOwner=$(
 				$SINFO_BIN -p "$PART" -h -o %N 	\
				| xargs -I NODES $SQUEUE_BIN "${SQUEUE_OPTS[@]}" --state="$STATE_RUNNING" -w NODES \
				| awk -v IGNORECASE=1 			\
				      -v ACCT="$ACCT"			\
				      -v RE_RUNNING="$RE_RUNNING"	\
				      '					\
					# Ignore this account, then count
					$5 == ACCT {next}
					$5 == "testpbs" {next}

					# Extract GPU counts from the Tres-Alloc field.
					# Note: this is a GAWK-ism, but that is ok.
					{
						match($8, /gpu=([0-9]+)/, buf);
						gpus = buf[1] + 0;
					}
					$6 ~ RE_RUNNING {
						RunningOwner += gpus;
					}
					END {
						printf("%d\n", RunningOwner);
					}
				      '					\
			)
			Free=$(( Total - RunningAll - StandbyGPUsUsedByOwner ))

			if [[ $verbo -gt 0 ]]; then
				warn "# Special account: $ACCT ($PART)"
				warn "# Total=$Total"
				warn "# RunningAll=$RunningAll"
				warn "# StandbyGPUsUsedByOwner=$StandbyGPUsUsedByOwner"
				warn "# Free=(Total - RunningAll - StandbyGPUsUsedByOwner) = ($Total - $RunningAll - $StandbyGPUsUsedByOwner) = $Free"
			fi
		fi

		# Sanity check
		if (( "$Free" < 0 )); then
			Free=0
		fi

		# Brush-up nodelist into comma-separated node types
		NODETYPES=$(nodelist2types "$NODELIST")

		# And print!
		printf  "$FORMAT" "$ACCT" "$Total" "$Queued" "$Running" "$Free" \
			"$WALLTIME" "${NODETYPES^^*}"
	done
	[[ $verbo -ge 0 ]] && echo
	return $E_OK
}


function nodelist2types() {
	# nodelist2types "nodelist" ["nodelist"...]
	# Convert Slurm/pdsh formatted nodelists ('mack-a00[0-9],mack-b00[0-3]')
	# into a comma-separated list of node types ('a,b').
	#   Arguments: 	node list(s)
	#   Output: 	Comma-separated list of node types
	# Note: RCAC-specific naming convention ('cluster-aNNN').

	# Combine all arguments into one comma-separated list
	local nodelist=$(printf "%s\n" "$@" | paste -s -d,)

	# And process
	local nodetypes=$(
		$SCONTROL_BIN show hostname "$nodelist" 2>/dev/null 	\
		| sed -e 's/^.*-//' -e 's/[0-9]*$//' 	\
		| grep -v '^[[:blank:]]' 		\
		| sort | uniq 				\
		| paste -s -d,
	)
	# Fall-back value... or just leave it empty
	# if [[ $? -ne 0 ]]; then
	# 	nodetypes="?"
	# fi
	echo "$nodetypes"
}


function assemble_gpuinfo_lines() {
	# sinfo ... | assemble_gpuinfo_lines
	# Depending on the requested output format, sinfo can print multiple
	# lines per partition (e.g. reporting nodes with different amounts of
	# GresUsed).  We need to fold them into a single line with A/I/O/T
	# data per partition (unlike for cores or nodes, Slurm provides no
	# such luxury for GRES).
	#   Input:      on stdin, expects (without header):
	#                 Partition   NodeAIOT      Gres          UsedGres     Nodelist
	#                 gilbreth-a  2/0/0/2   ...,gpu:2,...   ...,gpu:2,...  gilbreth-a[000-001]
	#                 gilbreth-a  1/0/0/1   ...,gpu:2,...   ...,gpu:1,...  gilbreth-a002
	#                 gilbreth-a  0/0/1/1   ...,gpu:2,...   ...,gpu:0,...  gilbreth-a003
	#   Arguments:  none (reads crafted sinfo output on stdin)
	#   Output:     flattened sinfo-style list, one line per partition,
	#               properly summed A/I/O/T GPU counts:
	#                 gilbreth-a  7/1/0/8 gilbreth-a[000,002-003],gilbreth-a001
	#
	# NB: this function is very tightly coupled with GPU_SINFO command.
	#
	# TODO: The "Idle = Total - Allocated - Offline" final correction
	#       might be a problem for overlapping partitions, needs checking.
	awk ' 	\
		{
		    # This chunk of a partition (Gres and UsedGres are per node)
		    part=$1;
		    split($2, aiot, "/");
		    match($3, "gpu:([0-9]+)",  hasgpus);  gputot=hasgpus[1];  	# [...,]gpu:123[,...]
		    match($4, "gpu:([0-9]+)", usesgpus); gpuused=usesgpus[1]; 	# [...,]gpu:123[,...]
		    nodelist=$5;

		    # Make a list of unique partition names in the order they were reported.
		    if (! PARTS[part]++) {
		        UNIQPARTS[length(PARTS)-1] = part
		    }

		    # Now add to global GPU counts for this partition
		    nodesAlloc   = aiot[1];
		    nodesIdle    = aiot[2];
		    nodesOffline = aiot[3];
		    nodesTotal   = aiot[4];
		    ALLOC[part]   += nodesAlloc   * gpuused  	# by *used* Gres
		    IDLE[part]    += nodesIdle    * gputot 	# often wrong, fix later
		    OFFLINE[part] += nodesOffline * gputot
		    TOTAL[part]   += nodesTotal   * gputot
		    # NB: Nodelist will have leading comma, will trim at the end
		    NODELIST[part] = NODELIST[part] "," nodelist;
		}

		END{
		   for (i=0; i<length(UNIQPARTS); i++) {
		       part=UNIQPARTS[i]
		       sub("^,*", "", NODELIST[part]); 	  # trim leading comma
		       # Idle count is not always correct (not sure why, but
		       # when less then all GPUs are allocated, the node is
		       # shown as
		       #     gilbreth-a  1/0/0/1  gpu:2  gpu:1"
		       # (i.e. occupied by one, but *not* also idle by one).
		       # Fixing in a crude "Idle = Total - Allocated - Offline"
		       # way.
		       #   TODO: This may be wrong for overlapping partitions.
		       IDLE[part] = TOTAL[part] - ALLOC[part] - OFFLINE[part]
		       printf("%s\t%d/%d/%d/%d\t%s\n",                       \
		              part, ALLOC[part], IDLE[part], OFFLINE[part],  \
		              TOTAL[part], NODELIST[part])
		   }
		}'
	return $?
}


function show_sfeatures() {
	# Prints a plug for sfeatures command if appropriate.

	# Not when extra quiet or when terse list output was requested
	[[ $verbo -lt 0 ]]         && return
	[[ "$OUTTYPE" == "list" ]] && return

	printf "Use 'sfeatures' command to see details on different node types.\n\n"
}


# ----------------------------------------------------------------------
# Log the invocation
# ----------------------------------------------------------------------
/bin/logger -t "$LOG_TAG" -- "user=$USER cmdline=$*"


# ----------------------------------------------------------------------
# Trap signals
# ----------------------------------------------------------------------
trap "signal_exit TERM" TERM HUP
trap "signal_exit INT"  INT


# ----------------------------------------------------------------------
# Parse command-line
# ----------------------------------------------------------------------
status=$E_OK 			# Hopefully ;-)
verbo=0 			# Default verbosity
Opt_Me=0 			# Show everyone's counts, not just this user's
Opt_AllAccts=0 			# Do not show all accounts (only this user's)
AntiList=0 			# Given option conflicts with '--list' option
declare -a ARGV
while [[ -n $1 ]]; do
	case "$1" in
		-a | --all)
			Opt_AllAccts=1 ;;
		-c | --cores | --cpus | --cpu)
			OUTTYPE='cores'; AntiList=1 ;;
		-g | --gpus | --gpu)
			OUTTYPE='gpus'; AntiList=1 ;;
		-l | --list)
			OUTTYPE='list'; Opt_List=1 ;;
		-j | --jobs | --job)
			OUTTYPE='jobs'; AntiList=1 ;;
		-m | --me)
			Opt_Me=1; AntiList=1 ;;
		-v | --verb | --verbo | --verbose)
			verbo=1 ;;
		-q | --quiet)
			verbo=-1 ;;
		-h | --help)
			help_message; graceful_exit ;;
		--)
			# A '--' encountered - slurping the rest as positionals
			shift; ARGV+=("$@"); break ;;
		-* | --*)
			warn -p "Unknown option '$1'"
			usage; error_exit '' $E_CMDLINE ;;
		*)
			ARGV+=("$1") ;; 	# Accumulate arguments
	esac
	shift
done
ARGC=${#ARGV[@]}

# Handle positional parameters, if given
# Not perfect, but consistent with 'qlist.pyx'.
if [[ $ARGC -gt 0 ]]; then
	if [[ ${ARGV[0]} == @* ]]; then
		CLUSTER="${ARGV[0]:1}" 		# Drop the first '@'
		if [[ -n ${ARGV[1]} ]]; then
			WHO="${ARGV[1]}"
		fi

	else
		WHO="${ARGV[0]}"
		if [[ -n ${ARGV[1]} && ${ARGV[1]} == @* ]]; then
			CLUSTER="${ARGV[1]:1}" 	# Drop the first '@'
		fi
	fi
fi


# ----------------------------------------------------------------------
# Read configuration file if present.
# A rudimentary chance to override behavioral defaults.
# ----------------------------------------------------------------------
set -o errexit 			# Temporary, for possible errors inside config
if [[ -e "$CONFFILE" ]]; then
	[[ $verbo -gt 0 ]] && warn "Reading configuration file $CONFFILE"
	source "$CONFFILE"
fi
set +o errexit


# ----------------------------------------------------------------------
# Defaults and sanity checks
# ----------------------------------------------------------------------
# Are we given any fish to fry?
if [[ $ARGC -gt 2 ]]; then
	warn -p "Extraneous arguments detected."
	usage; error_exit '' $E_CMDLINE
fi

# Output sanity checks
if [[ $Opt_List -ne 0 && $AntiList -ne 0 ]]; then
	warn -p "Incompatible output options."
	usage; error_exit '' $E_CMDLINE
fi

# More defaults
OUTTYPE="${OUTTYPE:-$OUTTYPE_DEF}"
WHO="${WHO:-$USER}"
[[ $verbo -gt 0 ]] && warn "Analyzing $OUTTYPE for $WHO"

# Required prerequisite commands, if any.
PREREQCMDS=( "$SACCTMGR_BIN" "$SQUEUE_BIN" "$SINFO_BIN" "$SCONTROL_BIN" )
for cmd in "${PREREQCMDS[@]}"; do
	assert_command_is_available "$cmd"
done

# Set cluster name.
# Querying FQDN and parsing "cluster-xxx" is a) RCAC-specific and b) unreliable
# on sub-subdomains like gateway.scholar.  Ask SLURM instead.
CLUSTER_DEF=$($SCONTROL_BIN --local show config | grep ^ClusterName | sed -e 's/^.*=[[:blank:]]*//')
CLUSTER="${CLUSTER:-$CLUSTER_DEF}"



# ----------------------------------------------------------------------
# Main logic
# ----------------------------------------------------------------------

# Populate global variables for accounts/limits/partitions/jobs information.
if ! populate_queue_variables; then
	error_exit "Could not query SLURM for necessary data, bailing out."
fi

# And perform output according to requested format
case "$OUTTYPE" in
	cores) 		output_cores "${ACCOUNTS[@]}" ;;
	 gpus) 		output_gpus  "${ACCOUNTS[@]}" ;;
	 jobs) 		output_jobs  "${ACCOUNTS[@]}" ;;
	 list) 		output_list  "${ACCOUNTS[@]}" ;;
	    *) 		error_exit "Unknow output type '$OUTTYPE' requested" ;;
esac
status=$?

# Promote 'sfeatures' if appropriate (not for all output types)
if [[ "$SHOW_SFEATURES" -ne 0 ]]; then
	show_sfeatures
fi


# ----------------------------------------------------------------------
# All done - exit.
# ----------------------------------------------------------------------
graceful_exit $status

